name: inference
nameOverride: ""
fullnameOverride: ""

replicaCount: 1

serviceAccount:
  create: true
  automount: true
  annotations: { }
  name: ""

image:
  name: microslac.io/inference
  tag: "latest"
  pullPolicy: IfNotPresent

persistent:
  storageClass: host
  volumeClaimName: huggingface-inference-pvc

config:
  data:
    modelId: "meta-llama/Meta-Llama-3-8B-Instruct"
    cudaMemoryFraction: "0.9"
    hostname: "0.0.0.0"

secret:
  data:
    huggingFaceHubToken: ""

service:
  type: ClusterIP
  port: 80

database:
  name: ""
  externalName: ""

resources:
  requests:
    cpu: 0.5
    memory: 254Mi
  limits:
    cpu: 1.0
    memory: 2048Mi

livenessProbe: null

readinessProbe: null

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80

volumes:
  - name: huggingface-hub
    persistentVolumeClaim:
      claimName: huggingface-inference-pvc

volumeMounts:
  - name: huggingface-hub
    mountPath: /data

nodeSelector: { }

tolerations: [ ]

affinity: { }
